{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Homebrew...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 1 tap (homebrew/core).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "arturo              gitlint             libslirp            pdm\n",
      "bit-git             googletest          ncspot              pickle\n",
      "blaze               gost                nicotine-plus       rain\n",
      "device-mapper       isort               node@14             taskwarrior-tui\n",
      "fnm                 libdrm              openjdk@8           vint\n",
      "gcalcli             libfuse             or-tools\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "Updated 785 formulae.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDeleted Formulae\u001b[0m\n",
      "boost@1.55                 meson-internal             woboq_codebrowser\n",
      "boost@1.59                 mysql-connector-c++@1.1\n",
      "llvm@6                     scw@1\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://homebrew.bintray.com/bottles/libomp-11.0.0.mojave.bottle\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://d29vzk4ow07wi7.cloudfront.net/0716db5d51938b2fae8ab\u001b[0m\n",
      "######################################################################## 100.0%#                  78.7%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libomp-11.0.0.mojave.bottle.tar.gz\u001b[0m\n",
      "üç∫  /usr/local/Cellar/libomp/11.0.0: 9 files, 1.4MB\n"
     ]
    }
   ],
   "source": [
    "#pip install xgboost\n",
    "!brew install libomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "#from surprise import Reader, Dataset\n",
    "#from surprise import BaselineOnly\n",
    "#from surprise import KNNBaseline\n",
    "#from surprise import SVD\n",
    "#from surprise import SVDpp\n",
    "#from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>read_time</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420507</td>\n",
       "      <td>16</td>\n",
       "      <td>1630</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1421031</td>\n",
       "      <td>1</td>\n",
       "      <td>685</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1421267</td>\n",
       "      <td>39</td>\n",
       "      <td>1908</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1421586</td>\n",
       "      <td>42</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1421620</td>\n",
       "      <td>50</td>\n",
       "      <td>3975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1429814</td>\n",
       "      <td>19</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1430005</td>\n",
       "      <td>15</td>\n",
       "      <td>4255</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1430246</td>\n",
       "      <td>40</td>\n",
       "      <td>946</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1430267</td>\n",
       "      <td>41</td>\n",
       "      <td>1726</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1430302</td>\n",
       "      <td>28</td>\n",
       "      <td>474</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  user_id  item_id  read_time  rating\n",
       "0        1420507       16     1630          2       4\n",
       "1        1421031        1      685          4       5\n",
       "2        1421267       39     1908          1       2\n",
       "3        1421586       42      242          1       3\n",
       "4        1421620       50     3975          1       3\n",
       "...          ...      ...      ...        ...     ...\n",
       "9995     1429814       19     1299          1       3\n",
       "9996     1430005       15     4255          1       2\n",
       "9997     1430246       40      946          4       4\n",
       "9998     1430267       41     1726          7       5\n",
       "9999     1430302       28      474          2       5\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_csv = pd.read_csv(\"news_corpus_processed.csv\")\n",
    "news_csv\n",
    "rating_csv = pd.read_csv(\"user_profile.csv\")\n",
    "rating_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_value = int(len(rating_csv) * 0.80)\n",
    "train_data = rating_csv[:split_value]\n",
    "test_data = rating_csv[split_value:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "ax = sns.countplot(x=\"rating\", data=train_data)\n",
    "\n",
    "ax.set_yticklabels([num for num in ax.get_yticks()])\n",
    "\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.title(\"Count Ratings in train data\", fontsize = 20)\n",
    "plt.xlabel(\"Ratings\", fontsize = 20)\n",
    "plt.ylabel(\"Number of Ratings\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_item_sparse_matrix(df):\n",
    "    sparse_data = sparse.csr_matrix((df.rating, (df.user_id, df.item_id)))\n",
    "    return sparse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<51x4655 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse_data = get_user_item_sparse_matrix(train_data)\n",
    "train_sparse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<51x4654 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sparse_data = get_user_item_sparse_matrix(test_data)\n",
    "test_sparse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Average Rating: 3.730465666929755\n"
     ]
    }
   ],
   "source": [
    "global_average_rating = train_sparse_data.sum()/train_sparse_data.count_nonzero()\n",
    "print(\"Global Average Rating: {}\".format(global_average_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_rating(sparse_matrix, is_user):\n",
    "    ax = 1 if is_user else 0\n",
    "    sum_of_ratings = sparse_matrix.sum(axis = ax).A1  \n",
    "    no_of_ratings = (sparse_matrix != 0).sum(axis = ax).A1 \n",
    "    rows, cols = sparse_matrix.shape\n",
    "    average_ratings = {i: sum_of_ratings[i]/no_of_ratings[i] for i in range(rows if is_user else cols) if no_of_ratings[i] != 0}\n",
    "    return average_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3.956140350877193,\n",
       " 2: 3.6923076923076925,\n",
       " 3: 3.8796296296296298,\n",
       " 4: 3.7358490566037736,\n",
       " 5: 3.9611650485436893,\n",
       " 6: 3.607594936708861,\n",
       " 7: 3.564814814814815,\n",
       " 8: 3.8210526315789473,\n",
       " 9: 3.5739130434782607,\n",
       " 10: 3.865979381443299,\n",
       " 11: 3.7009345794392523,\n",
       " 12: 3.657142857142857,\n",
       " 13: 3.888888888888889,\n",
       " 14: 3.6930693069306932,\n",
       " 15: 3.712962962962963,\n",
       " 16: 3.8842105263157896,\n",
       " 17: 3.6530612244897958,\n",
       " 18: 3.696629213483146,\n",
       " 19: 3.925233644859813,\n",
       " 20: 3.7362637362637363,\n",
       " 21: 3.7155963302752295,\n",
       " 22: 3.701923076923077,\n",
       " 23: 3.865546218487395,\n",
       " 24: 3.706422018348624,\n",
       " 25: 3.7448979591836733,\n",
       " 26: 3.8376068376068377,\n",
       " 27: 3.594059405940594,\n",
       " 28: 3.68,\n",
       " 29: 3.7663551401869158,\n",
       " 30: 3.5638297872340425,\n",
       " 31: 3.734042553191489,\n",
       " 32: 3.6666666666666665,\n",
       " 33: 3.89010989010989,\n",
       " 34: 3.6818181818181817,\n",
       " 35: 3.6557377049180326,\n",
       " 36: 3.7045454545454546,\n",
       " 37: 3.5625,\n",
       " 38: 3.68,\n",
       " 39: 3.814432989690722,\n",
       " 40: 3.776595744680851,\n",
       " 41: 3.616822429906542,\n",
       " 42: 3.945945945945946,\n",
       " 43: 3.857142857142857,\n",
       " 44: 3.541284403669725,\n",
       " 45: 3.625,\n",
       " 46: 3.5588235294117645,\n",
       " 47: 3.5961538461538463,\n",
       " 48: 3.5981308411214954,\n",
       " 49: 3.7572815533980584,\n",
       " 50: 3.868131868131868}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rating_user = get_average_rating(train_sparse_data, True)\n",
    "average_rating_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3026"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rating_news = get_average_rating(train_sparse_data, False)\n",
    "len(avg_rating_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 4.0,\n",
       " 4: 3.75,\n",
       " 5: 3.0,\n",
       " 6: 5.0,\n",
       " 7: 4.0,\n",
       " 8: 5.0,\n",
       " 13: 3.0,\n",
       " 15: 5.0,\n",
       " 16: 5.0,\n",
       " 17: 5.0,\n",
       " 18: 4.0,\n",
       " 22: 4.333333333333333,\n",
       " 23: 4.0,\n",
       " 25: 5.0,\n",
       " 27: 3.0,\n",
       " 34: 3.0,\n",
       " 35: 5.0,\n",
       " 38: 4.0,\n",
       " 39: 5.0,\n",
       " 41: 3.0,\n",
       " 42: 3.0,\n",
       " 43: 3.0,\n",
       " 45: 5.0,\n",
       " 47: 5.0,\n",
       " 48: 3.0,\n",
       " 52: 3.0,\n",
       " 53: 3.0,\n",
       " 54: 5.0,\n",
       " 58: 3.0,\n",
       " 60: 3.0,\n",
       " 61: 5.0,\n",
       " 62: 5.0,\n",
       " 64: 5.0,\n",
       " 69: 3.0,\n",
       " 70: 5.0,\n",
       " 72: 5.0,\n",
       " 76: 5.0,\n",
       " 78: 5.0,\n",
       " 79: 5.0,\n",
       " 80: 3.6666666666666665,\n",
       " 81: 5.0,\n",
       " 82: 5.0,\n",
       " 84: 5.0,\n",
       " 85: 4.0,\n",
       " 86: 4.333333333333333,\n",
       " 89: 5.0,\n",
       " 90: 3.0,\n",
       " 95: 3.0,\n",
       " 96: 5.0,\n",
       " 99: 5.0,\n",
       " 104: 5.0,\n",
       " 106: 4.0,\n",
       " 107: 3.0,\n",
       " 111: 5.0,\n",
       " 112: 5.0,\n",
       " 113: 5.0,\n",
       " 114: 3.0,\n",
       " 116: 5.0,\n",
       " 117: 5.0,\n",
       " 119: 3.0,\n",
       " 120: 5.0,\n",
       " 121: 3.0,\n",
       " 126: 3.0,\n",
       " 127: 5.0,\n",
       " 130: 3.0,\n",
       " 131: 3.0,\n",
       " 133: 5.0,\n",
       " 136: 2.0,\n",
       " 137: 5.0,\n",
       " 138: 5.0,\n",
       " 139: 3.6666666666666665,\n",
       " 140: 3.0,\n",
       " 141: 4.0,\n",
       " 142: 3.6666666666666665,\n",
       " 143: 5.0,\n",
       " 144: 3.6666666666666665,\n",
       " 146: 3.0,\n",
       " 147: 4.0,\n",
       " 148: 4.5,\n",
       " 149: 3.0,\n",
       " 151: 5.0,\n",
       " 152: 5.0,\n",
       " 153: 5.0,\n",
       " 156: 4.333333333333333,\n",
       " 157: 3.0,\n",
       " 158: 5.0,\n",
       " 159: 5.0,\n",
       " 161: 5.0,\n",
       " 162: 3.0,\n",
       " 163: 2.0,\n",
       " 164: 4.333333333333333,\n",
       " 167: 3.0,\n",
       " 168: 5.0,\n",
       " 169: 3.0,\n",
       " 170: 3.0,\n",
       " 171: 5.0,\n",
       " 175: 3.0,\n",
       " 176: 4.0,\n",
       " 178: 3.0,\n",
       " 179: 3.0,\n",
       " 181: 5.0,\n",
       " 183: 3.0,\n",
       " 184: 4.333333333333333,\n",
       " 185: 5.0,\n",
       " 187: 5.0,\n",
       " 191: 5.0,\n",
       " 194: 4.0,\n",
       " 195: 5.0,\n",
       " 198: 3.0,\n",
       " 199: 5.0,\n",
       " 200: 4.333333333333333,\n",
       " 203: 3.6666666666666665,\n",
       " 205: 3.0,\n",
       " 206: 3.0,\n",
       " 209: 2.0,\n",
       " 210: 3.0,\n",
       " 211: 3.0,\n",
       " 214: 5.0,\n",
       " 215: 4.0,\n",
       " 216: 3.0,\n",
       " 217: 5.0,\n",
       " 220: 4.333333333333333,\n",
       " 221: 4.0,\n",
       " 222: 3.0,\n",
       " 223: 3.0,\n",
       " 224: 4.333333333333333,\n",
       " 225: 5.0,\n",
       " 228: 4.0,\n",
       " 230: 4.0,\n",
       " 232: 5.0,\n",
       " 235: 3.0,\n",
       " 237: 4.0,\n",
       " 238: 5.0,\n",
       " 240: 3.0,\n",
       " 241: 5.0,\n",
       " 242: 3.0,\n",
       " 243: 3.6666666666666665,\n",
       " 244: 4.0,\n",
       " 245: 3.0,\n",
       " 246: 5.0,\n",
       " 247: 5.0,\n",
       " 249: 4.0,\n",
       " 252: 3.0,\n",
       " 253: 3.0,\n",
       " 255: 2.0,\n",
       " 256: 5.0,\n",
       " 258: 3.0,\n",
       " 259: 3.0,\n",
       " 261: 2.6666666666666665,\n",
       " 262: 4.333333333333333,\n",
       " 263: 5.0,\n",
       " 264: 5.0,\n",
       " 265: 4.333333333333333,\n",
       " 266: 3.0,\n",
       " 267: 3.0,\n",
       " 268: 3.0,\n",
       " 269: 5.0,\n",
       " 270: 5.0,\n",
       " 272: 4.5,\n",
       " 273: 4.0,\n",
       " 276: 2.5,\n",
       " 277: 3.0,\n",
       " 279: 4.0,\n",
       " 281: 3.3333333333333335,\n",
       " 282: 3.0,\n",
       " 285: 5.0,\n",
       " 286: 2.8,\n",
       " 289: 4.0,\n",
       " 290: 3.0,\n",
       " 292: 3.5,\n",
       " 296: 4.0,\n",
       " 297: 3.0,\n",
       " 298: 3.5,\n",
       " 299: 3.0,\n",
       " 300: 5.0,\n",
       " 301: 5.0,\n",
       " 303: 3.5,\n",
       " 305: 3.5,\n",
       " 306: 4.0,\n",
       " 307: 5.0,\n",
       " 309: 3.0,\n",
       " 310: 3.0,\n",
       " 311: 5.0,\n",
       " 313: 3.0,\n",
       " 316: 2.0,\n",
       " 317: 3.0,\n",
       " 319: 4.0,\n",
       " 320: 3.0,\n",
       " 321: 3.0,\n",
       " 322: 3.0,\n",
       " 323: 3.0,\n",
       " 324: 3.0,\n",
       " 325: 5.0,\n",
       " 328: 5.0,\n",
       " 329: 3.0,\n",
       " 330: 5.0,\n",
       " 331: 3.0,\n",
       " 334: 4.0,\n",
       " 336: 3.0,\n",
       " 337: 5.0,\n",
       " 339: 3.0,\n",
       " 342: 3.0,\n",
       " 345: 5.0,\n",
       " 349: 4.0,\n",
       " 351: 3.0,\n",
       " 352: 3.0,\n",
       " 353: 5.0,\n",
       " 355: 4.333333333333333,\n",
       " 356: 3.5,\n",
       " 357: 3.0,\n",
       " 358: 3.0,\n",
       " 360: 3.0,\n",
       " 361: 3.0,\n",
       " 363: 5.0,\n",
       " 364: 3.0,\n",
       " 365: 5.0,\n",
       " 366: 3.0,\n",
       " 368: 4.0,\n",
       " 369: 3.75,\n",
       " 370: 5.0,\n",
       " 371: 3.0,\n",
       " 373: 3.5,\n",
       " 374: 3.0,\n",
       " 379: 3.5,\n",
       " 382: 3.6666666666666665,\n",
       " 383: 3.0,\n",
       " 384: 3.0,\n",
       " 385: 3.0,\n",
       " 386: 3.0,\n",
       " 387: 3.6666666666666665,\n",
       " 388: 3.0,\n",
       " 389: 3.0,\n",
       " 391: 3.0,\n",
       " 392: 3.0,\n",
       " 394: 5.0,\n",
       " 395: 4.0,\n",
       " 397: 3.0,\n",
       " 398: 4.0,\n",
       " 399: 3.0,\n",
       " 400: 3.0,\n",
       " 401: 2.6666666666666665,\n",
       " 403: 3.0,\n",
       " 404: 5.0,\n",
       " 405: 3.0,\n",
       " 407: 5.0,\n",
       " 410: 4.0,\n",
       " 411: 4.0,\n",
       " 412: 3.0,\n",
       " 413: 3.3333333333333335,\n",
       " 414: 2.0,\n",
       " 415: 3.0,\n",
       " 417: 4.0,\n",
       " 418: 5.0,\n",
       " 419: 3.6,\n",
       " 421: 4.0,\n",
       " 423: 5.0,\n",
       " 425: 5.0,\n",
       " 426: 4.0,\n",
       " 427: 2.0,\n",
       " 428: 4.0,\n",
       " 429: 3.0,\n",
       " 431: 5.0,\n",
       " 433: 4.333333333333333,\n",
       " 435: 5.0,\n",
       " 436: 4.333333333333333,\n",
       " 439: 2.0,\n",
       " 440: 3.0,\n",
       " 441: 4.0,\n",
       " 442: 3.5,\n",
       " 443: 3.0,\n",
       " 444: 3.0,\n",
       " 450: 3.0,\n",
       " 452: 5.0,\n",
       " 453: 3.0,\n",
       " 455: 3.3333333333333335,\n",
       " 457: 5.0,\n",
       " 458: 5.0,\n",
       " 459: 4.0,\n",
       " 460: 3.0,\n",
       " 461: 4.5,\n",
       " 464: 5.0,\n",
       " 465: 4.0,\n",
       " 466: 4.0,\n",
       " 469: 4.5,\n",
       " 471: 3.0,\n",
       " 474: 4.0,\n",
       " 475: 4.0,\n",
       " 476: 4.333333333333333,\n",
       " 477: 2.6666666666666665,\n",
       " 478: 3.0,\n",
       " 479: 5.0,\n",
       " 480: 5.0,\n",
       " 484: 5.0,\n",
       " 485: 3.0,\n",
       " 486: 5.0,\n",
       " 488: 5.0,\n",
       " 489: 3.0,\n",
       " 490: 5.0,\n",
       " 491: 4.0,\n",
       " 492: 2.6666666666666665,\n",
       " 493: 4.333333333333333,\n",
       " 495: 5.0,\n",
       " 496: 2.0,\n",
       " 498: 3.0,\n",
       " 501: 2.0,\n",
       " 502: 5.0,\n",
       " 505: 3.2,\n",
       " 506: 4.0,\n",
       " 507: 5.0,\n",
       " 508: 3.25,\n",
       " 510: 3.0,\n",
       " 511: 4.0,\n",
       " 512: 5.0,\n",
       " 513: 2.0,\n",
       " 514: 5.0,\n",
       " 515: 4.0,\n",
       " 516: 3.0,\n",
       " 518: 3.0,\n",
       " 519: 5.0,\n",
       " 520: 4.333333333333333,\n",
       " 521: 3.5,\n",
       " 522: 3.25,\n",
       " 524: 5.0,\n",
       " 525: 4.0,\n",
       " 526: 5.0,\n",
       " 527: 3.5,\n",
       " 528: 5.0,\n",
       " 529: 4.0,\n",
       " 530: 5.0,\n",
       " 533: 3.0,\n",
       " 535: 3.0,\n",
       " 536: 5.0,\n",
       " 537: 4.0,\n",
       " 538: 5.0,\n",
       " 539: 4.5,\n",
       " 540: 3.0,\n",
       " 541: 3.0,\n",
       " 543: 5.0,\n",
       " 545: 3.0,\n",
       " 548: 2.0,\n",
       " 551: 3.0,\n",
       " 555: 3.0,\n",
       " 557: 3.0,\n",
       " 560: 3.0,\n",
       " 561: 3.0,\n",
       " 562: 4.0,\n",
       " 564: 3.0,\n",
       " 565: 3.0,\n",
       " 566: 3.0,\n",
       " 568: 3.0,\n",
       " 571: 3.0,\n",
       " 573: 3.6666666666666665,\n",
       " 574: 4.0,\n",
       " 575: 3.0,\n",
       " 578: 3.0,\n",
       " 581: 4.0,\n",
       " 582: 2.0,\n",
       " 583: 3.0,\n",
       " 584: 4.0,\n",
       " 586: 4.0,\n",
       " 587: 3.8,\n",
       " 588: 4.5,\n",
       " 589: 5.0,\n",
       " 591: 5.0,\n",
       " 592: 4.0,\n",
       " 594: 5.0,\n",
       " 596: 3.0,\n",
       " 597: 3.0,\n",
       " 599: 4.5,\n",
       " 601: 3.0,\n",
       " 602: 4.5,\n",
       " 605: 4.25,\n",
       " 606: 5.0,\n",
       " 607: 2.0,\n",
       " 608: 4.0,\n",
       " 610: 3.0,\n",
       " 611: 3.0,\n",
       " 614: 4.333333333333333,\n",
       " 617: 5.0,\n",
       " 618: 5.0,\n",
       " 619: 3.6666666666666665,\n",
       " 620: 4.0,\n",
       " 621: 4.0,\n",
       " 626: 3.0,\n",
       " 627: 5.0,\n",
       " 628: 4.5,\n",
       " 629: 3.0,\n",
       " 630: 3.0,\n",
       " 631: 4.0,\n",
       " 632: 3.75,\n",
       " 633: 5.0,\n",
       " 634: 5.0,\n",
       " 635: 3.5,\n",
       " 636: 5.0,\n",
       " 637: 3.0,\n",
       " 638: 5.0,\n",
       " 640: 4.0,\n",
       " 641: 4.333333333333333,\n",
       " 642: 5.0,\n",
       " 644: 3.0,\n",
       " 645: 5.0,\n",
       " 646: 2.0,\n",
       " 649: 3.0,\n",
       " 650: 3.0,\n",
       " 652: 5.0,\n",
       " 654: 4.0,\n",
       " 655: 3.0,\n",
       " 658: 3.0,\n",
       " 659: 5.0,\n",
       " 660: 5.0,\n",
       " 661: 3.0,\n",
       " 663: 3.0,\n",
       " 664: 5.0,\n",
       " 665: 5.0,\n",
       " 666: 4.666666666666667,\n",
       " 667: 4.0,\n",
       " 668: 4.0,\n",
       " 669: 3.0,\n",
       " 670: 5.0,\n",
       " 671: 3.0,\n",
       " 672: 3.0,\n",
       " 675: 4.0,\n",
       " 676: 5.0,\n",
       " 678: 4.333333333333333,\n",
       " 679: 3.0,\n",
       " 680: 3.0,\n",
       " 681: 5.0,\n",
       " 682: 2.0,\n",
       " 685: 4.5,\n",
       " 688: 3.0,\n",
       " 689: 1.5,\n",
       " 691: 2.5,\n",
       " 692: 5.0,\n",
       " 693: 5.0,\n",
       " 694: 5.0,\n",
       " 697: 2.0,\n",
       " 699: 5.0,\n",
       " 700: 3.0,\n",
       " 701: 3.0,\n",
       " 702: 2.0,\n",
       " 703: 2.0,\n",
       " 704: 3.0,\n",
       " 706: 4.0,\n",
       " 707: 5.0,\n",
       " 709: 3.25,\n",
       " 711: 5.0,\n",
       " 712: 5.0,\n",
       " 715: 5.0,\n",
       " 716: 2.0,\n",
       " 718: 3.0,\n",
       " 720: 3.3333333333333335,\n",
       " 722: 3.0,\n",
       " 723: 3.75,\n",
       " 724: 4.0,\n",
       " 730: 3.0,\n",
       " 731: 3.0,\n",
       " 732: 2.5,\n",
       " 733: 3.0,\n",
       " 735: 5.0,\n",
       " 736: 5.0,\n",
       " 737: 4.0,\n",
       " 738: 1.5,\n",
       " 739: 3.0,\n",
       " 740: 3.0,\n",
       " 742: 5.0,\n",
       " 743: 3.6666666666666665,\n",
       " 745: 2.0,\n",
       " 747: 5.0,\n",
       " 749: 2.0,\n",
       " 751: 2.0,\n",
       " 753: 5.0,\n",
       " 755: 3.5,\n",
       " 756: 4.0,\n",
       " 759: 3.0,\n",
       " 761: 4.0,\n",
       " 763: 1.0,\n",
       " 764: 2.0,\n",
       " 766: 4.0,\n",
       " 768: 2.5,\n",
       " 769: 3.0,\n",
       " 770: 4.0,\n",
       " 771: 4.0,\n",
       " 772: 3.0,\n",
       " 773: 5.0,\n",
       " 775: 3.0,\n",
       " 776: 4.5,\n",
       " 777: 5.0,\n",
       " 779: 2.6666666666666665,\n",
       " 782: 3.5,\n",
       " 783: 5.0,\n",
       " 785: 3.75,\n",
       " 786: 5.0,\n",
       " 789: 5.0,\n",
       " 790: 2.0,\n",
       " 792: 4.5,\n",
       " 794: 4.333333333333333,\n",
       " 795: 5.0,\n",
       " 797: 3.5,\n",
       " 799: 4.0,\n",
       " 800: 3.0,\n",
       " 801: 3.5,\n",
       " 802: 4.0,\n",
       " 803: 3.0,\n",
       " 807: 3.0,\n",
       " 808: 3.0,\n",
       " 810: 5.0,\n",
       " 811: 4.0,\n",
       " 812: 3.0,\n",
       " 813: 3.0,\n",
       " 814: 3.0,\n",
       " 815: 2.6666666666666665,\n",
       " 817: 5.0,\n",
       " 819: 3.6666666666666665,\n",
       " 820: 3.0,\n",
       " 821: 5.0,\n",
       " 822: 5.0,\n",
       " 823: 3.0,\n",
       " 830: 3.5,\n",
       " 831: 5.0,\n",
       " 832: 5.0,\n",
       " 833: 3.8,\n",
       " 834: 2.0,\n",
       " 835: 5.0,\n",
       " 836: 3.0,\n",
       " 837: 3.0,\n",
       " 838: 5.0,\n",
       " 839: 3.6666666666666665,\n",
       " 840: 5.0,\n",
       " 844: 4.0,\n",
       " 846: 5.0,\n",
       " 847: 5.0,\n",
       " 848: 2.0,\n",
       " 850: 4.0,\n",
       " 852: 3.0,\n",
       " 853: 1.5,\n",
       " 854: 2.5,\n",
       " 855: 3.3333333333333335,\n",
       " 856: 3.0,\n",
       " 859: 3.5,\n",
       " 861: 5.0,\n",
       " 862: 5.0,\n",
       " 865: 3.0,\n",
       " 869: 2.0,\n",
       " 870: 3.0,\n",
       " 871: 3.75,\n",
       " 872: 2.0,\n",
       " 873: 4.0,\n",
       " 875: 2.0,\n",
       " 876: 5.0,\n",
       " 877: 4.5,\n",
       " 878: 5.0,\n",
       " 879: 5.0,\n",
       " 880: 5.0,\n",
       " 882: 3.0,\n",
       " 883: 4.0,\n",
       " 885: 3.0,\n",
       " 886: 3.0,\n",
       " 887: 5.0,\n",
       " 888: 3.0,\n",
       " 889: 5.0,\n",
       " 890: 5.0,\n",
       " 891: 5.0,\n",
       " 892: 5.0,\n",
       " 893: 3.0,\n",
       " 898: 4.0,\n",
       " 899: 4.0,\n",
       " 901: 3.0,\n",
       " 902: 5.0,\n",
       " 903: 3.0,\n",
       " 904: 3.0,\n",
       " 906: 3.0,\n",
       " 908: 4.0,\n",
       " 910: 3.0,\n",
       " 911: 3.0,\n",
       " 912: 3.6666666666666665,\n",
       " 914: 3.6666666666666665,\n",
       " 915: 5.0,\n",
       " 918: 5.0,\n",
       " 919: 4.0,\n",
       " 920: 3.0,\n",
       " 925: 4.333333333333333,\n",
       " 926: 5.0,\n",
       " 927: 5.0,\n",
       " 928: 2.0,\n",
       " 929: 2.0,\n",
       " 930: 3.0,\n",
       " 931: 5.0,\n",
       " 932: 4.5,\n",
       " 933: 3.0,\n",
       " 935: 3.5,\n",
       " 936: 5.0,\n",
       " 938: 4.0,\n",
       " 939: 3.6666666666666665,\n",
       " 941: 5.0,\n",
       " 942: 1.0,\n",
       " 943: 5.0,\n",
       " 945: 5.0,\n",
       " 946: 1.5,\n",
       " 947: 3.0,\n",
       " 948: 5.0,\n",
       " 949: 3.0,\n",
       " 950: 3.0,\n",
       " 952: 5.0,\n",
       " 953: 3.0,\n",
       " 954: 4.0,\n",
       " 955: 3.0,\n",
       " 956: 2.0,\n",
       " 957: 5.0,\n",
       " 959: 4.0,\n",
       " 962: 5.0,\n",
       " 963: 3.0,\n",
       " 964: 3.0,\n",
       " 965: 5.0,\n",
       " 966: 4.0,\n",
       " 967: 3.5,\n",
       " 968: 4.0,\n",
       " 969: 3.0,\n",
       " 971: 1.0,\n",
       " 972: 5.0,\n",
       " 973: 5.0,\n",
       " 974: 5.0,\n",
       " 975: 3.0,\n",
       " 976: 5.0,\n",
       " 978: 5.0,\n",
       " 979: 4.0,\n",
       " 980: 4.333333333333333,\n",
       " 981: 3.0,\n",
       " 984: 2.0,\n",
       " 986: 2.0,\n",
       " 988: 5.0,\n",
       " 989: 3.0,\n",
       " 991: 4.0,\n",
       " 992: 4.5,\n",
       " 999: 2.6666666666666665,\n",
       " 1001: 5.0,\n",
       " 1004: 4.0,\n",
       " 1006: 3.0,\n",
       " 1008: 3.0,\n",
       " 1009: 5.0,\n",
       " 1010: 4.0,\n",
       " 1011: 4.0,\n",
       " 1012: 4.0,\n",
       " 1013: 3.0,\n",
       " 1014: 2.0,\n",
       " 1015: 5.0,\n",
       " 1019: 4.0,\n",
       " 1024: 3.0,\n",
       " 1025: 4.0,\n",
       " 1026: 5.0,\n",
       " 1032: 4.0,\n",
       " 1033: 3.0,\n",
       " 1034: 4.0,\n",
       " 1036: 4.0,\n",
       " 1039: 4.333333333333333,\n",
       " 1040: 5.0,\n",
       " 1047: 2.0,\n",
       " 1048: 4.0,\n",
       " 1050: 5.0,\n",
       " 1053: 3.0,\n",
       " 1055: 3.0,\n",
       " 1057: 5.0,\n",
       " 1060: 3.25,\n",
       " 1061: 3.6666666666666665,\n",
       " 1062: 4.0,\n",
       " 1063: 3.0,\n",
       " 1064: 3.0,\n",
       " 1065: 5.0,\n",
       " 1066: 3.0,\n",
       " 1067: 3.0,\n",
       " 1068: 3.0,\n",
       " 1070: 3.0,\n",
       " 1072: 3.6666666666666665,\n",
       " 1073: 3.0,\n",
       " 1074: 2.0,\n",
       " 1075: 3.5,\n",
       " 1076: 3.0,\n",
       " 1078: 3.0,\n",
       " 1079: 1.0,\n",
       " 1080: 3.6666666666666665,\n",
       " 1081: 3.5,\n",
       " 1085: 4.0,\n",
       " 1087: 5.0,\n",
       " 1088: 3.6666666666666665,\n",
       " 1089: 4.333333333333333,\n",
       " 1090: 4.0,\n",
       " 1091: 4.0,\n",
       " 1092: 3.2,\n",
       " 1093: 4.0,\n",
       " 1095: 5.0,\n",
       " 1097: 4.0,\n",
       " 1099: 3.0,\n",
       " 1101: 5.0,\n",
       " 1102: 4.0,\n",
       " 1103: 4.5,\n",
       " 1105: 3.0,\n",
       " 1106: 4.5,\n",
       " 1107: 3.0,\n",
       " 1108: 4.0,\n",
       " 1109: 3.0,\n",
       " 1110: 2.8,\n",
       " 1111: 4.0,\n",
       " 1117: 5.0,\n",
       " 1119: 3.0,\n",
       " 1120: 3.0,\n",
       " 1122: 5.0,\n",
       " 1123: 2.0,\n",
       " 1125: 2.0,\n",
       " 1126: 2.0,\n",
       " 1127: 2.5,\n",
       " 1130: 5.0,\n",
       " 1131: 3.0,\n",
       " 1133: 3.0,\n",
       " 1134: 3.0,\n",
       " 1135: 4.0,\n",
       " 1139: 2.0,\n",
       " 1140: 3.0,\n",
       " 1141: 1.75,\n",
       " 1143: 3.5,\n",
       " 1144: 4.0,\n",
       " 1145: 5.0,\n",
       " 1146: 1.5,\n",
       " 1147: 2.5,\n",
       " 1150: 5.0,\n",
       " 1151: 5.0,\n",
       " 1152: 5.0,\n",
       " 1153: 2.0,\n",
       " 1155: 3.0,\n",
       " 1156: 4.333333333333333,\n",
       " 1157: 2.0,\n",
       " 1158: 2.0,\n",
       " 1159: 3.0,\n",
       " 1162: 3.5,\n",
       " 1163: 4.0,\n",
       " 1164: 4.0,\n",
       " 1166: 1.0,\n",
       " 1169: 3.0,\n",
       " 1170: 3.3333333333333335,\n",
       " 1171: 5.0,\n",
       " 1174: 4.0,\n",
       " 1175: 4.0,\n",
       " 1178: 3.0,\n",
       " 1179: 3.3333333333333335,\n",
       " 1180: 3.0,\n",
       " 1181: 5.0,\n",
       " 1182: 3.75,\n",
       " 1183: 3.0,\n",
       " 1184: 5.0,\n",
       " 1185: 3.0,\n",
       " 1186: 4.0,\n",
       " 1188: 4.5,\n",
       " 1189: 3.5,\n",
       " 1191: 4.0,\n",
       " 1192: 3.5,\n",
       " 1193: 3.0,\n",
       " 1194: 4.5,\n",
       " 1195: 3.0,\n",
       " 1196: 2.0,\n",
       " 1197: 3.0,\n",
       " 1198: 4.0,\n",
       " 1201: 3.0,\n",
       " 1202: 3.0,\n",
       " 1205: 3.5,\n",
       " 1207: 5.0,\n",
       " 1209: 3.0,\n",
       " 1210: 4.333333333333333,\n",
       " 1211: 5.0,\n",
       " 1213: 3.0,\n",
       " 1214: 2.5,\n",
       " 1216: 3.0,\n",
       " 1220: 5.0,\n",
       " 1222: 4.5,\n",
       " 1223: 3.0,\n",
       " 1224: 3.6666666666666665,\n",
       " 1226: 5.0,\n",
       " 1228: 2.3333333333333335,\n",
       " 1229: 3.0,\n",
       " 1230: 3.0,\n",
       " 1232: 3.0,\n",
       " 1233: 3.0,\n",
       " 1236: 3.0,\n",
       " 1237: 5.0,\n",
       " 1239: 3.0,\n",
       " 1240: 5.0,\n",
       " 1243: 4.5,\n",
       " 1245: 5.0,\n",
       " 1246: 4.0,\n",
       " 1247: 5.0,\n",
       " 1248: 4.0,\n",
       " 1249: 3.0,\n",
       " 1253: 5.0,\n",
       " 1254: 3.3333333333333335,\n",
       " 1255: 4.5,\n",
       " 1257: 3.5,\n",
       " 1259: 4.75,\n",
       " 1260: 2.0,\n",
       " 1261: 1.0,\n",
       " 1262: 3.0,\n",
       " 1263: 3.5,\n",
       " 1264: 1.5,\n",
       " 1265: 2.0,\n",
       " 1266: 3.8333333333333335,\n",
       " 1267: 4.0,\n",
       " 1268: 3.0,\n",
       " 1269: 4.0,\n",
       " 1270: 3.6666666666666665,\n",
       " 1272: 3.5,\n",
       " 1275: 3.0,\n",
       " 1276: 5.0,\n",
       " 1277: 4.0,\n",
       " 1279: 2.0,\n",
       " 1283: 3.0,\n",
       " 1285: 3.0,\n",
       " 1286: 5.0,\n",
       " 1287: 4.0,\n",
       " 1289: 3.5,\n",
       " 1293: 2.0,\n",
       " 1294: 5.0,\n",
       " 1295: 4.0,\n",
       " 1296: 5.0,\n",
       " 1297: 5.0,\n",
       " 1299: 5.0,\n",
       " 1301: 5.0,\n",
       " 1305: 4.2,\n",
       " 1306: 3.0,\n",
       " 1309: 4.333333333333333,\n",
       " 1310: 4.0,\n",
       " 1311: 5.0,\n",
       " 1312: 5.0,\n",
       " 1314: 5.0,\n",
       " 1315: 4.0,\n",
       " 1317: 5.0,\n",
       " 1320: 3.0,\n",
       " 1321: 5.0,\n",
       " 1322: 5.0,\n",
       " 1323: 4.0,\n",
       " 1324: 4.0,\n",
       " 1325: 2.0,\n",
       " 1326: 2.0,\n",
       " 1328: 5.0,\n",
       " 1330: 4.0,\n",
       " 1331: 4.0,\n",
       " 1332: 5.0,\n",
       " 1334: 5.0,\n",
       " 1335: 5.0,\n",
       " 1336: 5.0,\n",
       " 1337: 2.0,\n",
       " 1338: 5.0,\n",
       " 1342: 3.0,\n",
       " 1343: 3.6666666666666665,\n",
       " 1344: 3.0,\n",
       " 1346: 3.3333333333333335,\n",
       " 1347: 3.6666666666666665,\n",
       " 1348: 5.0,\n",
       " 1349: 3.6666666666666665,\n",
       " 1350: 4.0,\n",
       " 1351: 5.0,\n",
       " 1352: 4.0,\n",
       " 1353: 4.0,\n",
       " 1356: 3.0,\n",
       " 1357: 2.0,\n",
       " 1358: 3.0,\n",
       " 1360: 5.0,\n",
       " 1361: 3.0,\n",
       " 1363: 3.6666666666666665,\n",
       " 1365: 2.5,\n",
       " 1366: 3.0,\n",
       " 1367: 4.0,\n",
       " 1368: 2.0,\n",
       " 1369: 4.0,\n",
       " 1370: 3.0,\n",
       " 1371: 4.0,\n",
       " 1372: 4.5,\n",
       " 1373: 4.0,\n",
       " 1376: 3.0,\n",
       " 1377: 2.6666666666666665,\n",
       " 1380: 5.0,\n",
       " 1382: 3.0,\n",
       " 1383: 3.0,\n",
       " 1384: 1.5,\n",
       " 1385: 4.0,\n",
       " 1386: 4.0,\n",
       " 1387: 4.333333333333333,\n",
       " 1388: 3.5,\n",
       " 1389: 3.0,\n",
       " 1390: 3.0,\n",
       " 1391: 2.0,\n",
       " 1392: 5.0,\n",
       " 1393: 5.0,\n",
       " 1394: 2.0,\n",
       " 1396: 3.0,\n",
       " 1397: 5.0,\n",
       " 1398: 2.0,\n",
       " 1401: 3.6666666666666665,\n",
       " 1402: 1.5,\n",
       " 1403: 3.0,\n",
       " 1404: 3.5,\n",
       " 1405: 4.0,\n",
       " 1408: 4.0,\n",
       " 1409: 4.0,\n",
       " 1412: 5.0,\n",
       " 1413: 3.0,\n",
       " 1415: 3.0,\n",
       " 1417: 5.0,\n",
       " 1419: 2.6666666666666665,\n",
       " 1421: 3.6666666666666665,\n",
       " 1422: 5.0,\n",
       " 1423: 5.0,\n",
       " 1424: 3.0,\n",
       " 1425: 5.0,\n",
       " 1426: 2.0,\n",
       " 1427: 3.5,\n",
       " 1428: 3.25,\n",
       " 1430: 3.0,\n",
       " 1432: 5.0,\n",
       " 1434: 4.333333333333333,\n",
       " 1435: 4.0,\n",
       " 1436: 3.5,\n",
       " 1437: 3.0,\n",
       " 1438: 3.0,\n",
       " 1439: 5.0,\n",
       " 1440: 4.0,\n",
       " 1442: 3.5,\n",
       " 1443: 3.25,\n",
       " 1444: 3.3333333333333335,\n",
       " 1445: 2.0,\n",
       " 1446: 5.0,\n",
       " 1447: 4.0,\n",
       " 1448: 5.0,\n",
       " 1449: 5.0,\n",
       " 1450: 4.0,\n",
       " 1451: 4.0,\n",
       " 1452: 2.0,\n",
       " 1453: 4.5,\n",
       " 1454: 3.0,\n",
       " 1455: 4.0,\n",
       " 1456: 3.0,\n",
       " 1457: 3.0,\n",
       " 1458: 2.0,\n",
       " 1460: 5.0,\n",
       " 1461: 4.0,\n",
       " 1462: 3.6666666666666665,\n",
       " 1463: 3.5,\n",
       " 1464: 3.5,\n",
       " 1465: 5.0,\n",
       " 1467: 5.0,\n",
       " 1468: 2.6666666666666665,\n",
       " 1469: 2.0,\n",
       " 1470: 2.5,\n",
       " 1471: 3.0,\n",
       " 1473: 2.0,\n",
       " 1474: 3.6666666666666665,\n",
       " 1476: 3.0,\n",
       " 1477: 3.0,\n",
       " 1479: 3.0,\n",
       " 1480: 3.0,\n",
       " 1481: 5.0,\n",
       " 1482: 3.0,\n",
       " 1483: 5.0,\n",
       " 1484: 3.0,\n",
       " 1485: 5.0,\n",
       " 1486: 4.666666666666667,\n",
       " 1487: 4.0,\n",
       " 1488: 5.0,\n",
       " 1490: 5.0,\n",
       " 1492: 2.0,\n",
       " 1493: 5.0,\n",
       " 1494: 3.0,\n",
       " 1495: 3.0,\n",
       " 1496: 5.0,\n",
       " 1497: 3.6666666666666665,\n",
       " 1498: 5.0,\n",
       " 1499: 5.0,\n",
       " 1500: 4.5,\n",
       " 1502: 5.0,\n",
       " 1503: 1.0,\n",
       " 1504: 5.0,\n",
       " 1506: 4.0,\n",
       " 1507: 3.0,\n",
       " 1508: 5.0,\n",
       " 1509: 5.0,\n",
       " 1510: 3.0,\n",
       " 1511: 3.0,\n",
       " 1514: 3.0,\n",
       " 1515: 3.0,\n",
       " 1517: 4.0,\n",
       " 1522: 3.0,\n",
       " 1523: 3.0,\n",
       " 1526: 4.0,\n",
       " 1528: 5.0,\n",
       " 1529: 4.0,\n",
       " 1530: 3.3333333333333335,\n",
       " 1532: 5.0,\n",
       " 1533: 5.0,\n",
       " 1535: 4.0,\n",
       " 1536: 3.5,\n",
       " 1537: 2.0,\n",
       " 1538: 3.0,\n",
       " 1540: 3.3333333333333335,\n",
       " 1541: 2.0,\n",
       " 1543: 4.5,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rating_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of Users = 50\n",
      "No. of Users in train data= 50\n",
      "No. of Users not present in train data = 0(0.0%)\n"
     ]
    }
   ],
   "source": [
    "total_users = len(np.unique(rating_csv[\"user_id\"]))\n",
    "train_users = len(average_rating_user)\n",
    "uncommonUsers = total_users - train_users\n",
    "                  \n",
    "print(\"Total no. of Users = {}\".format(total_users))\n",
    "print(\"No. of Users in train data= {}\".format(train_users))\n",
    "print(\"No. of Users not present in train data = {}({}%)\".format(uncommonUsers, np.round((uncommonUsers/total_users)*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of News Articles = 4150\n",
      "No. of News Articles in train data= 3026\n",
      "No. of News Articles not present in train data = 1124(27.0%)\n"
     ]
    }
   ],
   "source": [
    "total_news = len(np.unique(rating_csv[\"item_id\"]))\n",
    "train_news = len(avg_rating_news)\n",
    "uncommonNews = total_news - train_news\n",
    "                  \n",
    "print(\"Total no. of News Articles = {}\".format(total_news))\n",
    "print(\"No. of News Articles in train data= {}\".format(train_news))\n",
    "print(\"No. of News Articles not present in train data = {}({}%)\".format(uncommonNews, np.round((uncommonNews/total_news)*100), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_user_similarity(sparse_matrix, limit=51):\n",
    "    row_index, col_index = sparse_matrix.nonzero()\n",
    "    rows = np.unique(row_index)\n",
    "    similar_arr = np.zeros(31467).reshape(617,51)\n",
    "    \n",
    "    for row in rows[:limit]:\n",
    "        sim = cosine_similarity(sparse_matrix.getrow(row), train_sparse_data).ravel()\n",
    "        similar_indices = sim.argsort()[-limit:]\n",
    "        similar = sim[similar_indices]\n",
    "        similar_arr[row] = similar\n",
    "    \n",
    "    return similar_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_user_matrix = compute_user_similarity(train_sparse_data, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00279746, 0.00304328, 0.00403435, 0.00431029, 0.00448574,\n",
       "       0.00451217, 0.00699957, 0.00892239, 0.01202309, 0.01267643,\n",
       "       0.01298375, 0.01308065, 0.01317251, 0.01520157, 0.0175108 ,\n",
       "       0.0181843 , 0.01855857, 0.01864224, 0.01869664, 0.01920204,\n",
       "       0.01933806, 0.02013281, 0.02558575, 0.02591977, 0.02614693,\n",
       "       0.0297001 , 0.03020033, 0.03098341, 0.03134144, 0.03437583,\n",
       "       0.03621163, 0.03782558, 0.04051531, 0.04391623, 0.06331701,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_user_matrix[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4655"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_id</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uri box offic collect action star vicki kausha...</td>\n",
       "      <td>2019-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dosti ke side effect box offic collect day sap...</td>\n",
       "      <td>2019-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>late ranveer singh struck gold box offic look ...</td>\n",
       "      <td>2019-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gulli boy box offic predict accord girish joha...</td>\n",
       "      <td>2019-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gulli boy box offic collect day loos inspir li...</td>\n",
       "      <td>2019-02-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Article_id                                           Synopsis        Date\n",
       "0           1  uri box offic collect action star vicki kausha...  2019-02-08\n",
       "1           2  dosti ke side effect box offic collect day sap...  2019-02-09\n",
       "2           3  late ranveer singh struck gold box offic look ...  2019-02-14\n",
       "3           4  gulli boy box offic predict accord girish joha...  2019-02-14\n",
       "4           5  gulli boy box offic collect day loos inspir li...  2019-02-15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_heading = news_csv[[\"Article_id\",\"Synopsis\", \"Date\"]]\n",
    "news_heading.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_news_similarity_count(sparse_matrix, news_heading, article_id):\n",
    "    similarity = cosine_similarity(sparse_matrix.T, dense_output = False)\n",
    "    no_of_similar_articles = news_heading.loc[article_id][1], similarity[article_id].count_nonzero()\n",
    "    return no_of_similar_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar News Articles = ('gulli boy box offic predict accord girish johar gulli boy loos base life mumbai street rapper naezi divin set cash regist ring first day', 201)\n"
     ]
    }
   ],
   "source": [
    "similar_articles = compute_news_similarity_count(train_sparse_data, news_heading, 3)\n",
    "print(\"Similar News Articles = {}\".format(similar_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_sparse_matrix(sparse_matrix, no_of_users, no_of_news):\n",
    "    users, news_articles, ratings = sparse.find(sparse_matrix)\n",
    "    print( news_articles.shape)\n",
    "    uniq_users = np.unique(users)\n",
    "    print(uniq_users.shape)\n",
    "    uniq_news = np.unique(news_articles)\n",
    "    print(uniq_news.shape)\n",
    "    np.random.seed(15) \n",
    "    user = np.random.choice(uniq_users, no_of_users, replace = False)\n",
    "    print(len(users))\n",
    "    news = np.random.choice(uniq_news, no_of_news, replace = True)\n",
    "    print(\"USERS\",users)\n",
    "    mask = np.logical_and(np.isin(users, user), np.isin(news_articles, news))\n",
    "    sparse_matrix = sparse.csr_matrix((ratings[mask], (users[mask], news_articles[mask])), \n",
    "                                                     shape = (max(user)+1, max(news)+1))\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068,)\n",
      "(50,)\n",
      "(3026,)\n",
      "5068\n",
      "USERS [ 7 10  5 ... 36 31 48]\n"
     ]
    }
   ],
   "source": [
    "train_sample_sparse_matrix = get_sample_sparse_matrix(train_sparse_data, 50, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 1062)\t3\n",
      "  (4, 1486)\t5\n",
      "  (5, 3652)\t5\n",
      "  (5, 3947)\t3\n",
      "  (5, 4282)\t3\n",
      "  (6, 1486)\t5\n",
      "  (7, 2015)\t4\n",
      "  (8, 621)\t3\n",
      "  (8, 738)\t1\n",
      "  (8, 2431)\t3\n",
      "  (8, 3996)\t3\n",
      "  (9, 3836)\t2\n",
      "  (10, 464)\t5\n",
      "  (10, 2437)\t5\n",
      "  (11, 3836)\t5\n",
      "  (11, 4093)\t5\n",
      "  (12, 3884)\t3\n",
      "  (14, 1482)\t3\n",
      "  (15, 2624)\t3\n",
      "  (15, 4582)\t2\n",
      "  (16, 1348)\t5\n",
      "  (16, 1630)\t4\n",
      "  (16, 3996)\t5\n",
      "  (17, 397)\t3\n",
      "  (17, 3996)\t5\n",
      "  :\t:\n",
      "  (29, 1482)\t3\n",
      "  (30, 152)\t5\n",
      "  (30, 1715)\t3\n",
      "  (31, 621)\t5\n",
      "  (31, 3506)\t5\n",
      "  (32, 2104)\t3\n",
      "  (33, 1348)\t5\n",
      "  (33, 3652)\t5\n",
      "  (36, 3996)\t3\n",
      "  (40, 2323)\t5\n",
      "  (40, 2624)\t3\n",
      "  (40, 3947)\t3\n",
      "  (41, 2890)\t5\n",
      "  (42, 1715)\t5\n",
      "  (42, 3675)\t4\n",
      "  (44, 2015)\t5\n",
      "  (44, 3675)\t4\n",
      "  (45, 397)\t3\n",
      "  (45, 2766)\t5\n",
      "  (47, 634)\t5\n",
      "  (48, 2766)\t4\n",
      "  (49, 4368)\t3\n",
      "  (50, 1943)\t5\n",
      "  (50, 2741)\t3\n",
      "  (50, 2766)\t2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51, 4583)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_sample_sparse_matrix)\n",
    "train_sample_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299,)\n",
      "(50,)\n",
      "(1127,)\n",
      "1299\n",
      "USERS [28 34 47 ... 39  5 40]\n"
     ]
    }
   ],
   "source": [
    "test_sparse_matrix_matrix = get_sample_sparse_matrix(test_sparse_data, 50, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (4, 1397)\t5\n",
      "  (7, 1561)\t5\n",
      "  (7, 2990)\t3\n",
      "  (11, 393)\t5\n",
      "  (12, 4586)\t1\n",
      "  (13, 1211)\t2\n",
      "  (15, 442)\t5\n",
      "  (15, 1051)\t2\n",
      "  (20, 2436)\t2\n",
      "  (20, 4444)\t3\n",
      "  (22, 1344)\t4\n",
      "  (22, 2129)\t5\n",
      "  (22, 4342)\t3\n",
      "  (25, 1586)\t3\n",
      "  (27, 2043)\t3\n",
      "  (33, 442)\t2\n",
      "  (33, 1033)\t5\n",
      "  (33, 1881)\t5\n",
      "  (36, 2667)\t5\n",
      "  (38, 442)\t5\n",
      "  (39, 3929)\t5\n",
      "  (46, 1912)\t3\n",
      "  (50, 1912)\t3\n"
     ]
    }
   ],
   "source": [
    "print(test_sparse_matrix_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_similar_features(sample_sparse_matrix):\n",
    "    global_avg_rating = get_average_rating(sample_sparse_matrix, False)\n",
    "    global_avg_users = get_average_rating(sample_sparse_matrix, True)\n",
    "    global_avg_news = get_average_rating(sample_sparse_matrix, False)\n",
    "    sample_train_users, sample_train_news, sample_train_ratings = sparse.find(sample_sparse_matrix)\n",
    "    new_features_csv_file = open(\"new_features.csv\", mode = \"w\")\n",
    "    \n",
    "    for user, news, rating in zip(sample_train_users, sample_train_news, sample_train_ratings):\n",
    "        similar_arr = list()\n",
    "        similar_arr.append(user)\n",
    "        similar_arr.append(news)\n",
    "        similar_arr.append(sample_sparse_matrix.sum()/sample_sparse_matrix.count_nonzero())\n",
    "        \n",
    "        similar_users = cosine_similarity(sample_sparse_matrix[user], sample_sparse_matrix).ravel()\n",
    "        indices = np.argsort(-similar_users)[1:]\n",
    "        ratings = sample_sparse_matrix[indices, news].toarray().ravel()\n",
    "        #print(ratings)\n",
    "        top_similar_user_ratings = list(ratings[ratings != 0][:1])\n",
    "       # print(top_similar_user_ratings)\n",
    "        top_similar_user_ratings.extend([global_avg_rating[news]] * (1 - len(ratings)))\n",
    "        similar_arr.extend(top_similar_user_ratings)\n",
    "        \n",
    "        similar_news = cosine_similarity(sample_sparse_matrix[:,news].T, sample_sparse_matrix.T).ravel()\n",
    "        similar_news_indices = np.argsort(-similar_news)[1:]\n",
    "        similar_news_ratings = sample_sparse_matrix[user, similar_news_indices].toarray().ravel()\n",
    "        top_similar_news_ratings = list(similar_news_ratings[similar_news_ratings != 0][:1])\n",
    "        #print(\"yugh\",top_similar_news_ratings)\n",
    "        top_similar_news_ratings.extend([global_avg_users[user]] * (1-len(top_similar_news_ratings)))\n",
    "        similar_arr.extend(top_similar_news_ratings)\n",
    "        \n",
    "        similar_arr.append(global_avg_users[user])\n",
    "        similar_arr.append(global_avg_news[news])\n",
    "        similar_arr.append(rating)\n",
    "       # print(rating)\n",
    "        new_features_csv_file.write(\",\".join(map(str, similar_arr)))\n",
    "        new_features_csv_file.write(\"\\n\")\n",
    "        \n",
    "    new_features_csv_file.close()\n",
    "    new_features_df = pd.read_csv('new_features.csv', names = [\"user_id\", \"article_id\", \"gloabl_average\", \"similar_user_rating1\",\n",
    "                                                                \"similar_news_rating\", \"user_average\",\"news_average\" ,\"rating\"])\n",
    "    return new_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_similar_features = create_new_similar_features(train_sample_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  article_id  gloabl_average  similar_user_rating1  \\\n",
      "0        30         152        3.846154                   3.0   \n",
      "1        17         397        3.846154                   3.0   \n",
      "2        45         397        3.846154                   3.0   \n",
      "3        10         464        3.846154                   5.0   \n",
      "4        22         533        3.846154                   3.0   \n",
      "..      ...         ...             ...                   ...   \n",
      "60       11        4093        3.846154                   5.0   \n",
      "61        5        4282        3.846154                   3.0   \n",
      "62       49        4368        3.846154                   3.0   \n",
      "63       15        4582        3.846154                   4.0   \n",
      "64       24        4582        3.846154                   2.0   \n",
      "\n",
      "    similar_news_rating  user_average  news_average  rating  \n",
      "0              4.000000           5.0           5.0     NaN  \n",
      "1              5.000000           4.0           3.0     3.0  \n",
      "2              5.000000           4.0           3.0     3.0  \n",
      "3              5.000000           5.0           5.0     NaN  \n",
      "4              3.000000           3.0           3.0     NaN  \n",
      "..                  ...           ...           ...     ...  \n",
      "60             5.000000           5.0           5.0     NaN  \n",
      "61             3.666667           3.0           3.0     NaN  \n",
      "62             3.000000           3.0           3.0     NaN  \n",
      "63             3.000000           2.5           3.0     2.0  \n",
      "64             5.000000           4.5           3.0     4.0  \n",
      "\n",
      "[65 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_new_similar_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_similar_features = create_new_similar_features(test_sparse_matrix_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>gloabl_average</th>\n",
       "      <th>similar_user_rating1</th>\n",
       "      <th>similar_news_rating</th>\n",
       "      <th>user_average</th>\n",
       "      <th>news_average</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>393</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>442</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>442</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>442</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1033</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id  gloabl_average  similar_user_rating1  \\\n",
       "0       11         393        3.652174                   5.0   \n",
       "1       15         442        3.652174                   5.0   \n",
       "2       33         442        3.652174                   5.0   \n",
       "3       38         442        3.652174                   5.0   \n",
       "4       33        1033        3.652174                   5.0   \n",
       "\n",
       "   similar_news_rating  user_average  news_average  rating  \n",
       "0                  5.0           5.0           5.0     0.0  \n",
       "1                  2.0           3.5           4.0     5.0  \n",
       "2                  5.0           4.0           4.0     2.0  \n",
       "3                  5.0           5.0           4.0     5.0  \n",
       "4                  4.0           5.0           5.0     0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_similar_features = test_new_similar_features.fillna(0)\n",
    "test_new_similar_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_new_similar_features.drop([\"user_id\", \"article_id\",\"rating\"], axis = 1)\n",
    "\n",
    "x_test = test_new_similar_features.drop([\"user_id\", \"article_id\", \"rating\"], axis = 1)\n",
    "\n",
    "y_train = train_new_similar_features[\"rating\"]\n",
    "\n",
    "y_test = test_new_similar_features[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:36:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=10, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBRegressor(n_estimators = 100, silent = False, n_jobs  = 10)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.611777306874781\n"
     ]
    }
   ],
   "source": [
    "rmse_test = error_metrics(y_test, y_pred_test)\n",
    "print(\"RMSE = {}\".format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
